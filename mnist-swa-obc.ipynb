{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:50:40.687561Z",
     "iopub.status.busy": "2024-11-24T14:50:40.687301Z",
     "iopub.status.idle": "2024-11-24T14:50:45.042835Z",
     "shell.execute_reply": "2024-11-24T14:50:45.042103Z",
     "shell.execute_reply.started": "2024-11-24T14:50:40.687534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.quantization import quantize_dynamic\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:50:45.044458Z",
     "iopub.status.busy": "2024-11-24T14:50:45.044099Z",
     "iopub.status.idle": "2024-11-24T14:50:50.17622Z",
     "shell.execute_reply": "2024-11-24T14:50:50.175472Z",
     "shell.execute_reply.started": "2024-11-24T14:50:45.044432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "data_dir = '/kaggle/input/digit-recognizer/'\n",
    "raw_df = pd.read_csv(data_dir + 'train.csv')\n",
    "test_df = pd.read_csv(data_dir + 'test.csv')\n",
    "sub_df = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "\n",
    "input_cols = raw_df.columns.tolist()\n",
    "input_cols.remove('label')\n",
    "target_col = 'label'\n",
    "\n",
    "for col in input_cols:\n",
    "    raw_df[col] = raw_df[col] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class AugmentedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.images[idx], self.labels[idx]\n",
    "        img = T.ToPILImage()(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 데이터 변환\n",
    "train_transforms = T.Compose([\n",
    "    T.RandomHorizontalFlip(),     \n",
    "    T.RandomRotation(15),         \n",
    "    T.RandomCrop(32, padding=4),  \n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), \n",
    "    T.ToTensor(),               \n",
    "])\n",
    "\n",
    "val_transforms = T.Compose([\n",
    "    T.ToTensor(),              \n",
    "])\n",
    "\n",
    "input_tensor = torch.tensor(raw_df[input_cols].values, dtype=torch.float32).reshape(-1, 1, 28, 28)\n",
    "target_tensor = torch.tensor(raw_df[target_col].values)\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_ds = AugmentedDataset(input_tensor, target_tensor, transform=train_transforms)\n",
    "val_ds = AugmentedDataset(input_tensor, target_tensor, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:50:50.177555Z",
     "iopub.status.busy": "2024-11-24T14:50:50.177279Z",
     "iopub.status.idle": "2024-11-24T14:50:50.197632Z",
     "shell.execute_reply": "2024-11-24T14:50:50.196912Z",
     "shell.execute_reply.started": "2024-11-24T14:50:50.17753Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 훈련 및 검증 데이터 분할\n",
    "val_size = 8000\n",
    "train_size = len(train_ds) - val_size\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "train_ds, val_ds = random_split(train_ds, [train_size, val_size])\n",
    "\n",
    "# DataLoader 생성\n",
    "batch_size = 128\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size * 2, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:50:50.199868Z",
     "iopub.status.busy": "2024-11-24T14:50:50.199566Z",
     "iopub.status.idle": "2024-11-24T14:50:50.236476Z",
     "shell.execute_reply": "2024-11-24T14:50:50.235617Z",
     "shell.execute_reply.started": "2024-11-24T14:50:50.199838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# GPU 사용 설정\n",
    "def get_default_device():\n",
    "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device = get_default_device()\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            yield to_device(batch, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:50:50.237821Z",
     "iopub.status.busy": "2024-11-24T14:50:50.237532Z",
     "iopub.status.idle": "2024-11-24T14:50:50.251104Z",
     "shell.execute_reply": "2024-11-24T14:50:50.250322Z",
     "shell.execute_reply.started": "2024-11-24T14:50:50.237795Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    ]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prep = conv_block(1, 64)\n",
    "        self.layer1 = conv_block(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "        self.layer2 = conv_block(128, 256, pool=True)\n",
    "        self.layer3 = conv_block(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, xb):\n",
    "        out = self.prep(xb)\n",
    "        out = self.layer1(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:50:50.252342Z",
     "iopub.status.busy": "2024-11-24T14:50:50.252101Z",
     "iopub.status.idle": "2024-11-24T14:50:50.506053Z",
     "shell.execute_reply": "2024-11-24T14:50:50.505351Z",
     "shell.execute_reply.started": "2024-11-24T14:50:50.252318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "cnn_model = to_device(CNNModel(), device)\n",
    "swa_model = AveragedModel(cnn_model)\n",
    "\n",
    "# 옵티마이저 및 SWA 설정\n",
    "base_optimizer = torch.optim.AdamW(cnn_model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "swa_scheduler = SWALR(base_optimizer, anneal_strategy=\"cos\", anneal_epochs=5, swa_lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:50:50.507289Z",
     "iopub.status.busy": "2024-11-24T14:50:50.50702Z",
     "iopub.status.idle": "2024-11-24T14:50:50.514408Z",
     "shell.execute_reply": "2024-11-24T14:50:50.513594Z",
     "shell.execute_reply.started": "2024-11-24T14:50:50.507263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fit_swa_pruning(epochs, swa_start, model, swa_model, train_dl, val_dl, optimizer, scheduler, pruning_amount=0.5):\n",
    "    \"\"\"\n",
    "    SWA 학습 및 가지치기를 포함한 학습 함수.\n",
    "    가지치기는 SWA 업데이트 이후에 수행합니다.\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_dl:\n",
    "            images, labels = batch\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            # 역전파 및 그래디언트 클리핑\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # 클리핑 추가\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "        # SWA 업데이트 (swa_start 이후)\n",
    "        if epoch >= swa_start:\n",
    "            swa_model.update_parameters(model)\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_acc = evaluate_model(model, val_dl)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {sum(train_losses)/len(train_losses):.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        history.append((val_loss, val_acc))\n",
    "\n",
    "    # 가지치기 적용\n",
    "    print(\"Applying pruning after SWA training...\")\n",
    "    for module_name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            prune.l1_unstructured(module, name=\"weight\", amount=pruning_amount)\n",
    "            print(f\"Pruned layer {module_name}\")\n",
    "\n",
    "    # BatchNorm 통계 업데이트\n",
    "    print(\"Updating BatchNorm statistics after pruning...\")\n",
    "    update_bn(train_dl, swa_model)\n",
    "    \n",
    "    return history, swa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:50:50.515892Z",
     "iopub.status.busy": "2024-11-24T14:50:50.515546Z",
     "iopub.status.idle": "2024-11-24T14:50:50.526439Z",
     "shell.execute_reply": "2024-11-24T14:50:50.525815Z",
     "shell.execute_reply.started": "2024-11-24T14:50:50.515855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 평가 함수\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, val_dl):\n",
    "    model.eval()\n",
    "    val_loss, val_acc = 0, 0\n",
    "    for batch in val_dl:\n",
    "        images, labels = batch\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        val_loss += loss.item()\n",
    "        val_acc += acc.item()\n",
    "    return val_loss / len(val_dl), val_acc / len(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:50:50.527454Z",
     "iopub.status.busy": "2024-11-24T14:50:50.527216Z",
     "iopub.status.idle": "2024-11-24T15:02:28.721743Z",
     "shell.execute_reply": "2024-11-24T15:02:28.720252Z",
     "shell.execute_reply.started": "2024-11-24T14:50:50.527428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 학습 실행\n",
    "epochs = 200\n",
    "swa_start = 150\n",
    "history, swa_model = fit_swa_pruning(epochs, swa_start, cnn_model, swa_model, train_dl, val_dl, base_optimizer, swa_scheduler)\n",
    "\n",
    "# SWA 모델 평가\n",
    "val_loss, val_acc = evaluate_model(swa_model, val_dl)\n",
    "print(f\"SWA Model - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-24T15:02:28.722777Z",
     "iopub.status.idle": "2024-11-24T15:02:28.723109Z",
     "shell.execute_reply": "2024-11-24T15:02:28.722976Z",
     "shell.execute_reply.started": "2024-11-24T15:02:28.722959Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 가지치기 결과 확인\n",
    "print(\"Verifying pruning sparsity...\")\n",
    "for module_name, module in cnn_model.named_modules():\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        print(f\"Layer {module_name} sparsity: {torch.sum(module.weight == 0) / module.weight.numel():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3. 양자화 (Quantization)\n",
    "print(\"Applying dynamic quantization...\")\n",
    "cpu_model = swa_model.module.to('cpu')  # SWA 모델을 CPU로 이동\n",
    "quantized_model = quantize_dynamic(\n",
    "    cpu_model,  # CPU에서 동작하도록 설정\n",
    "    {nn.Linear, nn.Conv2d},  # 양자화할 레이어\n",
    "    dtype=torch.qint8  # 데이터 타입 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 모델 크기 계산\n",
    "def calculate_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def calculate_model_size(model, dtype=torch.float32):\n",
    "    \"\"\"\n",
    "    모델의 메모리 사용량(MB)을 계산하는 함수.\n",
    "    dtype에 따라 torch.finfo 또는 torch.iinfo를 사용하여 데이터 타입의 비트를 계산합니다.\n",
    "    \"\"\"\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    if dtype.is_floating_point:  # 부동소수점 타입\n",
    "        bits = torch.finfo(dtype).bits\n",
    "    else:  # 정수 타입\n",
    "        bits = torch.iinfo(dtype).bits\n",
    "    size_in_bytes = num_params * bits / 8\n",
    "    return size_in_bytes / (1024 * 1024)  # MB로 변환\n",
    "\n",
    "\n",
    "original_size = calculate_model_size(cnn_model)\n",
    "quantized_size = calculate_model_size(quantized_model, dtype=torch.qint8)\n",
    "\n",
    "print(f\"Original Model Size: {original_size:.2f} MB\")\n",
    "print(f\"Quantized Model Size: {quantized_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가지치기 전 원래 모델 복사본 생성\n",
    "original_model = CNNModel().to(device)  # 동일한 초기 모델 정의\n",
    "\n",
    "# FLOPs 계산\n",
    "flops_original = calculate_flops_with_fvcore(original_model, input_tensor)\n",
    "flops_pruned = calculate_flops_with_fvcore(cnn_model, input_tensor)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Original Model FLOPs: {flops_original / 1e6:.2f} MFLOPs\")\n",
    "print(f\"Pruned Model FLOPs: {flops_pruned / 1e6:.2f} MFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가지치기 전 모델 추론 속도\n",
    "inference_time_original = measure_inference_time(original_model, input_tensor, device=device)\n",
    "\n",
    "# 가지치기 후 모델 추론 속도\n",
    "inference_time_pruned = measure_inference_time(cnn_model, input_tensor, device=device)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Original Model Inference Time: {inference_time_original:.2f} ms\")\n",
    "print(f\"Pruned Model Inference Time: {inference_time_pruned:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-24T15:02:28.724189Z",
     "iopub.status.idle": "2024-11-24T15:02:28.724469Z",
     "shell.execute_reply": "2024-11-24T15:02:28.724348Z",
     "shell.execute_reply.started": "2024-11-24T15:02:28.724334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 예측 (CPU에서 실행)\n",
    "print(\"Preparing test dataset...\")\n",
    "test_df[input_cols] = test_df[input_cols] / 255\n",
    "test_input_tensors = torch.tensor(test_df[input_cols].values, dtype=torch.float32).reshape(-1, 1, 28, 28)\n",
    "test_input_tensors = T.Resize((32, 32))(test_input_tensors)\n",
    "test_ds = TensorDataset(test_input_tensors)\n",
    "\n",
    "def predict_image(img, model):\n",
    "    \"\"\"\n",
    "    한 이미지를 받아 모델로 예측 결과를 반환하는 함수.\n",
    "    \"\"\"\n",
    "    xb = img.unsqueeze(0)  # 배치를 만듦\n",
    "    yb = model(xb)  # 모델 예측\n",
    "    _, preds = torch.max(yb, dim=1)  # 예측 클래스 반환\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 예측 및 결과 저장\n",
    "print(\"Generating predictions (CPU)...\")\n",
    "sub_df['Label'] = [predict_image(test_ds[i][0], quantized_model) for i in range(len(test_ds))]\n",
    "\n",
    "# 제출 파일 저장\n",
    "submission_path = '/kaggle/working/submission.csv'\n",
    "sub_df.to_csv(submission_path, index=False)\n",
    "print(f\"Submission file saved to {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
