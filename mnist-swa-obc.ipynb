{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nimport matplotlib.pyplot as plt\nfrom torch.optim.swa_utils import AveragedModel, SWALR, update_bn\nimport torch.nn.utils.prune as prune\nfrom torch.quantization import quantize_dynamic","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:50:40.687301Z","iopub.execute_input":"2024-11-24T14:50:40.687561Z","iopub.status.idle":"2024-11-24T14:50:45.042835Z","shell.execute_reply.started":"2024-11-24T14:50:40.687534Z","shell.execute_reply":"2024-11-24T14:50:45.042103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 데이터 로드 및 전처리\ndata_dir = '/kaggle/input/digit-recognizer/'\nraw_df = pd.read_csv(data_dir + 'train.csv')\ntest_df = pd.read_csv(data_dir + 'test.csv')\nsub_df = pd.read_csv(data_dir + 'sample_submission.csv')\n\ninput_cols = raw_df.columns.tolist()\ninput_cols.remove('label')\ntarget_col = 'label'\n\nfor col in input_cols:\n    raw_df[col] = raw_df[col] / 255\n\ninput_tensor = torch.tensor(raw_df[input_cols].values, dtype=torch.float32)\ntarget_tensor = torch.tensor(raw_df[target_col].values)\n\ninput_tensor = input_tensor.reshape(-1, 1, 28, 28)\ninput_tensor = T.Resize((32, 32))(input_tensor)\n\nraw_ds = TensorDataset(input_tensor, target_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:50:45.044099Z","iopub.execute_input":"2024-11-24T14:50:45.044458Z","iopub.status.idle":"2024-11-24T14:50:50.17622Z","shell.execute_reply.started":"2024-11-24T14:50:45.044432Z","shell.execute_reply":"2024-11-24T14:50:50.175472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 훈련 및 검증 데이터 분할\nval_size = 8000\ntrain_size = len(raw_ds) - val_size\nrandom_seed = 42\ntorch.manual_seed(random_seed)\n\ntrain_ds, val_ds = random_split(raw_ds, [train_size, val_size])\nbatch_size = 128\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size * 2, num_workers=4, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:50:50.177279Z","iopub.execute_input":"2024-11-24T14:50:50.177555Z","iopub.status.idle":"2024-11-24T14:50:50.197632Z","shell.execute_reply.started":"2024-11-24T14:50:50.17753Z","shell.execute_reply":"2024-11-24T14:50:50.196912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# GPU 사용 설정\ndef get_default_device():\n    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice = get_default_device()\n\ndef to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n\n    def __iter__(self):\n        for batch in self.dl:\n            yield to_device(batch, self.device)\n\n    def __len__(self):\n        return len(self.dl)\n\ntrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:50:50.199566Z","iopub.execute_input":"2024-11-24T14:50:50.199868Z","iopub.status.idle":"2024-11-24T14:50:50.236476Z","shell.execute_reply.started":"2024-11-24T14:50:50.199838Z","shell.execute_reply":"2024-11-24T14:50:50.235617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 모델 정의\ndef conv_block(in_channels, out_channels, pool=False):\n    layers = [\n        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(inplace=True)\n    ]\n    if pool:\n        layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.prep = conv_block(1, 64)\n        self.layer1 = conv_block(64, 128, pool=True)\n        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n        self.layer2 = conv_block(128, 256, pool=True)\n        self.layer3 = conv_block(256, 512, pool=True)\n        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n        self.classifier = nn.Sequential(\n            nn.MaxPool2d(4),\n            nn.Flatten(),\n            nn.Dropout(0.2),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, xb):\n        out = self.prep(xb)\n        out = self.layer1(out)\n        out = self.res1(out) + out\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.res2(out) + out\n        out = self.classifier(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:50:50.237532Z","iopub.execute_input":"2024-11-24T14:50:50.237821Z","iopub.status.idle":"2024-11-24T14:50:50.251104Z","shell.execute_reply.started":"2024-11-24T14:50:50.237795Z","shell.execute_reply":"2024-11-24T14:50:50.250322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 모델 초기화\ncnn_model = to_device(CNNModel(), device)\nswa_model = AveragedModel(cnn_model)\n\n# 옵티마이저 및 SWA 설정\nbase_optimizer = torch.optim.AdamW(cnn_model.parameters(), lr=0.01, weight_decay=1e-4)\nswa_scheduler = SWALR(base_optimizer, anneal_strategy=\"cos\", anneal_epochs=5, swa_lr=0.005)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:50:50.252101Z","iopub.execute_input":"2024-11-24T14:50:50.252342Z","iopub.status.idle":"2024-11-24T14:50:50.506053Z","shell.execute_reply.started":"2024-11-24T14:50:50.252318Z","shell.execute_reply":"2024-11-24T14:50:50.505351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fit_swa_pruning(epochs, swa_start, model, swa_model, train_dl, val_dl, optimizer, scheduler, pruning_amount=0.5):\n    \"\"\"\n    SWA 학습 및 가지치기를 포함한 학습 함수.\n    가지치기는 SWA 업데이트 이후에 수행합니다.\n    \"\"\"\n    torch.cuda.empty_cache()\n    history = []\n\n    for epoch in range(epochs):\n        model.train()\n        train_losses = []\n        for batch in train_dl:\n            images, labels = batch\n            outputs = model(images)\n            loss = F.cross_entropy(outputs, labels)\n            train_losses.append(loss.item())\n            \n            # 역전파 및 그래디언트 클리핑\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # 클리핑 추가\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            scheduler.step()\n\n        # SWA 업데이트 (swa_start 이후)\n        if epoch >= swa_start:\n            swa_model.update_parameters(model)\n\n        # Validation\n        val_loss, val_acc = evaluate_model(model, val_dl)\n        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {sum(train_losses)/len(train_losses):.4f}, \"\n              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n        history.append((val_loss, val_acc))\n\n    # 가지치기 적용\n    print(\"Applying pruning after SWA training...\")\n    for module_name, module in model.named_modules():\n        if isinstance(module, nn.Conv2d):\n            prune.l1_unstructured(module, name=\"weight\", amount=pruning_amount)\n            print(f\"Pruned layer {module_name}\")\n\n    # BatchNorm 통계 업데이트\n    print(\"Updating BatchNorm statistics after pruning...\")\n    update_bn(train_dl, swa_model)\n    \n    return history, swa_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:50:50.50702Z","iopub.execute_input":"2024-11-24T14:50:50.507289Z","iopub.status.idle":"2024-11-24T14:50:50.514408Z","shell.execute_reply.started":"2024-11-24T14:50:50.507263Z","shell.execute_reply":"2024-11-24T14:50:50.513594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 평가 함수\n@torch.no_grad()\ndef evaluate_model(model, val_dl):\n    model.eval()\n    val_loss, val_acc = 0, 0\n    for batch in val_dl:\n        images, labels = batch\n        outputs = model(images)\n        loss = F.cross_entropy(outputs, labels)\n        _, preds = torch.max(outputs, dim=1)\n        acc = (preds == labels).float().mean()\n        val_loss += loss.item()\n        val_acc += acc.item()\n    return val_loss / len(val_dl), val_acc / len(val_dl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:50:50.515546Z","iopub.execute_input":"2024-11-24T14:50:50.515892Z","iopub.status.idle":"2024-11-24T14:50:50.526439Z","shell.execute_reply.started":"2024-11-24T14:50:50.515855Z","shell.execute_reply":"2024-11-24T14:50:50.525815Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 학습 실행\nepochs = 200\nswa_start = 150\nhistory, swa_model = fit_swa_pruning(epochs, swa_start, cnn_model, swa_model, train_dl, val_dl, base_optimizer, swa_scheduler)\n\n# SWA 모델 평가\nval_loss, val_acc = evaluate_model(swa_model, val_dl)\nprint(f\"SWA Model - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:50:50.527216Z","iopub.execute_input":"2024-11-24T14:50:50.527454Z","iopub.status.idle":"2024-11-24T15:02:28.721743Z","shell.execute_reply.started":"2024-11-24T14:50:50.527428Z","shell.execute_reply":"2024-11-24T15:02:28.720252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 가지치기 결과 확인\nprint(\"Verifying pruning sparsity...\")\nfor module_name, module in cnn_model.named_modules():\n    if isinstance(module, nn.Conv2d):\n        print(f\"Layer {module_name} sparsity: {torch.sum(module.weight == 0) / module.weight.numel():.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:02:28.722777Z","iopub.status.idle":"2024-11-24T15:02:28.723109Z","shell.execute_reply.started":"2024-11-24T15:02:28.722959Z","shell.execute_reply":"2024-11-24T15:02:28.722976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. 양자화 (Quantization)\nprint(\"Applying dynamic quantization...\")\ncpu_model = swa_model.module.to('cpu')  # SWA 모델을 CPU로 이동\nquantized_model = quantize_dynamic(\n    cpu_model,  # CPU에서 동작하도록 설정\n    {nn.Linear, nn.Conv2d},  # 양자화할 레이어\n    dtype=torch.qint8  # 데이터 타입 설정\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 모델 크기 계산\ndef calculate_parameters(model):\n    return sum(p.numel() for p in model.parameters())\n\ndef calculate_model_size(model, dtype=torch.float32):\n    \"\"\"\n    모델의 메모리 사용량(MB)을 계산하는 함수.\n    dtype에 따라 torch.finfo 또는 torch.iinfo를 사용하여 데이터 타입의 비트를 계산합니다.\n    \"\"\"\n    num_params = sum(p.numel() for p in model.parameters())\n    if dtype.is_floating_point:  # 부동소수점 타입\n        bits = torch.finfo(dtype).bits\n    else:  # 정수 타입\n        bits = torch.iinfo(dtype).bits\n    size_in_bytes = num_params * bits / 8\n    return size_in_bytes / (1024 * 1024)  # MB로 변환\n\n\noriginal_size = calculate_model_size(cnn_model)\nquantized_size = calculate_model_size(quantized_model, dtype=torch.qint8)\n\nprint(f\"Original Model Size: {original_size:.2f} MB\")\nprint(f\"Quantized Model Size: {quantized_size:.2f} MB\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 테스트 데이터 예측 (CPU에서 실행)\nprint(\"Preparing test dataset...\")\ntest_df[input_cols] = test_df[input_cols] / 255\ntest_input_tensors = torch.tensor(test_df[input_cols].values, dtype=torch.float32).reshape(-1, 1, 28, 28)\ntest_input_tensors = T.Resize((32, 32))(test_input_tensors)\ntest_ds = TensorDataset(test_input_tensors)\n\ndef predict_image(img, model):\n    \"\"\"\n    한 이미지를 받아 모델로 예측 결과를 반환하는 함수.\n    \"\"\"\n    xb = img.unsqueeze(0)  # 배치를 만듦\n    yb = model(xb)  # 모델 예측\n    _, preds = torch.max(yb, dim=1)  # 예측 클래스 반환\n    return preds[0].item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:02:28.724189Z","iopub.status.idle":"2024-11-24T15:02:28.724469Z","shell.execute_reply.started":"2024-11-24T15:02:28.724334Z","shell.execute_reply":"2024-11-24T15:02:28.724348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 테스트 데이터 예측 및 결과 저장\nprint(\"Generating predictions (CPU)...\")\nsub_df['Label'] = [predict_image(test_ds[i][0], quantized_model) for i in range(len(test_ds))]\n\n# 제출 파일 저장\nsubmission_path = '/kaggle/working/submission.csv'\nsub_df.to_csv(submission_path, index=False)\nprint(f\"Submission file saved to {submission_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}